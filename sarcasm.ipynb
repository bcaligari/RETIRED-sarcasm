{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARcasm\n",
    "\n",
    "**A Jupyter notebook for helping [me] make sense of sysstat sar data.**\n",
    "\n",
    "Copyright (c) 2017 Brendon Caligari, London, UK\n",
    "\n",
    "    This program is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "    \n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "    \n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\n",
    "Strategy:\n",
    "* Export one, or possibly more, sysstat ```.sa``` files as XML\n",
    "* Import the sar data from XML into pandas dataframes\n",
    "* Provide reference code for manipulation and visualisation of the various metrics\n",
    "\n",
    "Tested and assumed to work with:\n",
    "* SLES 11 SP[34]\n",
    "* Ubuntu 16.4\n",
    "\n",
    "### Usage\n",
    "\n",
    "As sysstat evolved so did the file format used to stor the sar data and unfortunately there is no guarantee that a version of ```sadf``` can read ```.sa``` files created with an earlier version of ```sa```.  Thankfully, different versions of sar data file format and sysstat version used can be determined from the file header.\n",
    "```sadf``` can export ```.sa``` files into various formats.  XML outpout has been available *consistently* since [at least] sysstat version 8.1.5 and proved to be the most umambiquous and complete format for this script's objectives.\n",
    "\n",
    "#### Sysstat binaries\n",
    "\n",
    "For every ```.sa``` file version an ```sadf``` binary capable of exporting its contents to XML is required.  This mapping from file version to binary is maintained in the dict ```sa_exporters``` class variable for class ```SarData```.\n",
    "\n",
    "#### Files to analyse\n",
    "\n",
    "Which ```.sa``` files to analyse and the directory where they are found is set in the ```sa_files``` list and the ```sa_directory``` variables respectively in the **Importing sa files** sections.  It is sensible that consequitive daily sar files from the same host are used for a meaningful time series.\n",
    "\n",
    "#### Analysing the data\n",
    "\n",
    "The section **Sanity checks** outputs metadata collected from the input files and describes the data frames used to store the collected information.  The **Plots** section provides templates for frequently rquired plot.  The idea however is for those plots to be modified or added to as required.\n",
    "\n",
    "#### System requirements\n",
    "\n",
    "* Python3\n",
    "* Jupyter\n",
    "* pandas\n",
    "* Should be fine with Anaconda [Python3]\n",
    "\n",
    "### KNOWN ISSUES\n",
    "\n",
    "* **This is a bodged together ugly hack not a proper application**\n",
    "* We are rudely abusing XML both in principle and practice\n",
    "* TODO compile a table of known file formats and compatible sysstat versions\n",
    "* TODO include link to ```sysstat``` versions\n",
    "* TODO include links to various sysstat binary downloads\n",
    "* Heavy refactoring is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sa_directory = './z2'\n",
    "sa_files = [\"sa04\", \"sa05\", \"sa06\", 'sa07', 'sa08', 'sa09', 'sa10', 'sa11', 'sa12', 'sa13', 'sa14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SarData(object):\n",
    "    \"\"\"Class for importing sar data\"\"\"\n",
    "    \n",
    "    sa_file_magic = \"96d5\"\n",
    "    \n",
    "    sa_exporters = {\n",
    "        \"2170\": [\"./sadf.binaries/sles11sp3/usr/bin/sadf\", \"-x\", \"-t\", \"--\", \"-A\"],\n",
    "        \"2173\": [\"/usr/bin/sadf\", \"-x\", \"-t\", \"--\", \"-A\"]\n",
    "    }\n",
    "\n",
    "    @classmethod\n",
    "    def sa_get_version(cls, filename):\n",
    "        \"\"\"Checks an sa file for sysstat sa magic and returns file format version\"\"\"\n",
    "        with open(filename, mode=\"rb\") as f:\n",
    "            magic = f.read(2)\n",
    "            if magic != bytes.fromhex(cls.sa_file_magic):\n",
    "                raise TypeError(\"{} does not start with sa file magic. Got 0x{:02x}{:02x}\".format(\n",
    "                    filename, magic[1], magic[0]))\n",
    "            format_version = f.read(2)\n",
    "            return \"{:02x}{:02x}\".format(format_version[1], format_version[0])\n",
    "\n",
    "    @classmethod\n",
    "    def sa_to_xml(cls, filename):\n",
    "        \"\"\"Open an sa file and export it to XML\"\"\"\n",
    "        sa_ver = cls.sa_get_version(filename)\n",
    "        if not sa_ver in cls.sa_exporters:\n",
    "            raise NotImplementedError(\"No exporter for {} format version {}\".format(filename, sa_ver))\n",
    "        return subprocess.check_output(cls.sa_exporters[sa_ver] + [filename])\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.hostname = None            # hostname within sa file\n",
    "        self.aggregate0 = None          # aggregate of what we pull out of the xml\n",
    "        self.aggregate1 = None\n",
    "        self.hostmeta = None\n",
    "        self._raw_aggregate0 = list()\n",
    "        self._raw_metadata = list()\n",
    "        \n",
    "    def import_file(self, filename):\n",
    "        \"\"\"Import an sa file\"\"\"\n",
    "        # XML output from sadf seems to have developed 'evolutionarily' with namespaces\n",
    "        # thrown in at some point for added inconvenience.  Here we strip them out.\n",
    "        raw_xml = self.sa_to_xml(filename)      # Read in the xml output of sadf\n",
    "        xml_tree = ET.fromstring(raw_xml)       # Convert to ET elements\n",
    "        __class__._strip_xml_ns(xml_tree)       # Remove XML namespace crap inplace\n",
    "        if xml_tree.tag != \"sysstat\":\n",
    "            raise TypeError(\"Expected 'sysstat' but found a root of {}\".format(xml_tree.tag))\n",
    "        for level1 in xml_tree:\n",
    "            if level1.tag == 'sysdata-version':\n",
    "                pass\n",
    "            elif level1.tag == \"host\":\n",
    "                tmp_hostmeta = {'filename': filename}\n",
    "                if \"nodename\" in level1.attrib:\n",
    "                    tmp_hostmeta['nodename'] = level1.attrib[\"nodename\"]\n",
    "                for host_child in level1:\n",
    "                    if host_child.tag == \"statistics\":\n",
    "                        for timestamp in host_child:\n",
    "                            if timestamp.tag != \"timestamp\":\n",
    "                                print(\"  Unexpected statistic tag: {}\".timestamp.tag)\n",
    "                                continue\n",
    "                            datum_time = datetime.strptime(timestamp.attrib[\"date\"] +\n",
    "                                                           \"T\" + timestamp.attrib[\"time\"],\n",
    "                                                           \"%Y-%m-%dT%H:%M:%S\")\n",
    "                            tmp_datum0 = {'timestamp': datum_time}\n",
    "                            for metric in timestamp:\n",
    "                                metric_parser = self.get_metric_parser(metric.tag)\n",
    "                                if metric_parser:\n",
    "                                    tmp_datum0.update(metric_parser(metric))\n",
    "                            self._raw_aggregate0.append(tmp_datum0)\n",
    "                    else:\n",
    "                        hostmeta_parser = self.get_hostmeta_parser(host_child.tag)\n",
    "                        if hostmeta_parser:\n",
    "                            tmp_hostmeta[host_child.tag] = hostmeta_parser(host_child)\n",
    "                        else:\n",
    "                            print(\"Unexpected host tag: {}\".format(host_child.tag))\n",
    "                self._raw_metadata.append(tmp_hostmeta)\n",
    "            else:\n",
    "                print(\"Unknown level 1: {}\".format(child_tag))\n",
    "        pass\n",
    "        \n",
    "    def dicts_to_dataframes(self):\n",
    "        \"\"\"Convert the various temporary lists of dicts to Data Frames\"\"\"\n",
    "        self.aggregate0 = pd.DataFrame.from_dict(self._raw_aggregate0)\n",
    "        self.hostmeta = pd.DataFrame.from_dict(self._raw_metadata)\n",
    "    \n",
    "    def fix_numeric_columns(self):\n",
    "        \"\"\"Convert necessary Data Frame columns from str to numeric\"\"\"\n",
    "        for sa_column in self.aggregate0.columns:\n",
    "            if sa_column == 'timestamp':\n",
    "                continue\n",
    "            sa.aggregate0[sa_column] = pd.to_numeric(sa.aggregate0[sa_column],\n",
    "                                                     errors='coerce')\n",
    "\n",
    "    @classmethod\n",
    "    def _strip_xml_ns(cls, element):\n",
    "        element.tag = element.tag.split('}')[-1]\n",
    "        for child in element:\n",
    "            cls._strip_xml_ns(child)\n",
    "\n",
    "    @classmethod\n",
    "    def get_hostmeta_parser(cls, meta_tag):\n",
    "        \"\"\"Returns a parser for Elements under 'host'\"\"\"\n",
    "        ## we can comment out any problematic ones at runtime\n",
    "        meta_parsers ={\n",
    "            'sysname': cls._parse_meta_default,\n",
    "            'release': cls._parse_meta_default,\n",
    "            'comments': cls._parse_meta_default,\n",
    "            'restarts': cls._parse_meta_default,\n",
    "            'machine': cls._parse_meta_default,\n",
    "            'number-of-cpus': cls._parse_meta_default,\n",
    "            'file-date': cls._parse_meta_default,\n",
    "            'file-utc-time': cls._parse_meta_default\n",
    "        }\n",
    "        if meta_tag in meta_parsers:\n",
    "            return meta_parsers[meta_tag]\n",
    "        return None\n",
    "        \n",
    "    @classmethod\n",
    "    def get_metric_parser(cls, metric_tag):\n",
    "        \"\"\"Returns a parser for Elements under 'host->statistics'\"\"\"\n",
    "        ## we can comment out any problematic ones at runtime\n",
    "        metric_parsers = {\n",
    "            'queue': cls._parse_metric_queue,\n",
    "            'memory': cls._parse_metric_memory,\n",
    "            'process-and-context-switch': cls._parse_metric_proc_cswch,\n",
    "            'hugepages': cls._parse_metric_hugepages,\n",
    "            'paging': cls._parse_metric_paging,\n",
    "            'io': cls._parse_metric_io,\n",
    "            'swap-pages': cls._parse_metric_swap_pages\n",
    "        }\n",
    "        if metric_tag in metric_parsers:\n",
    "            return metric_parsers[metric_tag]\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_meta_default(element):\n",
    "        return element.text.strip()\n",
    "    \n",
    "    @staticmethod\n",
    "    def _parse_metric_queue(element):\n",
    "        \"\"\"runq and load averages\"\"\"\n",
    "        ## runq-sz|plist-sz|ldavg-1|ldavg-5|ldavg-15\n",
    "        return element.attrib.copy()\n",
    "    \n",
    "    @staticmethod\n",
    "    def _parse_metric_memory(element):\n",
    "        \"\"\"memory statistics\"\"\"\n",
    "        ## memfree|memused|memused-percent|buffers|cached|commit|commit-percent\n",
    "        ## swpfree|swpused|swpused-percent|swpcad|swpcad-percent|frmpg|bufpg|campg\n",
    "        assert(element.attrib['per'] == 'second' and element.attrib['unit'] == 'kB')\n",
    "        tmp_dict = dict()\n",
    "        for memstat in element:\n",
    "            tmp_dict[memstat.tag] = memstat.text\n",
    "        return tmp_dict\n",
    "    \n",
    "    @staticmethod\n",
    "    def _parse_metric_proc_cswch(element):\n",
    "        \"\"\"process and context switch\"\"\"\n",
    "        ## proc|cswch\n",
    "        ## Note: 'per' is an attrib we don't need\n",
    "        assert(element.attrib['per'] == 'second')\n",
    "        tmp_dict = element.attrib.copy()\n",
    "        tmp_dict.pop('per')\n",
    "        return tmp_dict\n",
    "    \n",
    "    @staticmethod\n",
    "    def _parse_metric_hugepages(element):\n",
    "        \"\"\"huge pages\"\"\"\n",
    "        ## hugfree|hugused|hugused-percent\n",
    "        assert(element.attrib['unit'] == \"kB\")\n",
    "        tmp_dict = dict()\n",
    "        for hpstat in element:\n",
    "            tmp_dict[hpstat.tag] = hpstat.text\n",
    "        return tmp_dict\n",
    "    \n",
    "    @staticmethod\n",
    "    def _parse_metric_paging(element):\n",
    "        \"\"\"paging statistics\"\"\"\n",
    "        assert(element.attrib['per'] == \"second\")\n",
    "        ## paging pgpgin|pgpgout|fault|majflt|pgfree|pgscank|pgscand|pgsteal|vmeff-percent\n",
    "        tmp_dict = element.attrib.copy()\n",
    "        tmp_dict.pop('per')\n",
    "        return tmp_dict\n",
    "    \n",
    "    @staticmethod\n",
    "    def _parse_metric_io(element):\n",
    "        \"\"\"io metrics\"\"\"\n",
    "        ## tps | rtps | bread | wtps | bwrtn\n",
    "        assert(element.attrib['per'] == \"second\")\n",
    "        tmp_dict = dict()\n",
    "        for iostat in element:\n",
    "            if iostat.tag == \"tps\":\n",
    "                tmp_dict[iostat.tag] = iostat.text\n",
    "            else:\n",
    "                tmp_dict.update(iostat.attrib.copy())\n",
    "        return tmp_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_metric_swap_pages(element):\n",
    "        \"\"\"swap pages\"\"\"\n",
    "        ## pswpin|pswpout\n",
    "        assert(element.attrib['per'] == 'second')\n",
    "        tmp_dict = element.attrib.copy()\n",
    "        tmp_dict.pop('per')\n",
    "        return tmp_dict\n",
    "    \n",
    "    def plot_simple_aggregate0(self, y_vars):\n",
    "        \"\"\"simple timeseries from self.aggregate0 columns\"\"\"\n",
    "        plot = None\n",
    "        try:\n",
    "            sa.aggregate0.plot(x=['timestamp'],\n",
    "                               y=y_vars,\n",
    "                               style='-',\n",
    "                               figsize=(15, 10))\n",
    "        except KeyError as err:\n",
    "            print(\"KeyError: {}\".format(err))\n",
    "        return plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing ```sa``` files\n",
    "\n",
    "Here we extract the various entries within the sar file and populate appropriate data frames.  The process is deliberately iterative and verbose to expose the various fields and make on the fly modification or manual reproduction of steps easier. *It does however need to be heavily refactored regardless.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SarData()\n",
    "\n",
    "for sa_file in map(lambda sa_file: \"{}/{}\".format(sa_directory, sa_file), sa_files):\n",
    "    sa_xml = sa.import_file(sa_file)\n",
    "\n",
    "sa.dicts_to_dataframes()\n",
    "sa.fix_numeric_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.hostmeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sa.aggregate0.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Queue length and load averages\n",
    "* ```ldavg-1``` - System load average over past 1 minute\n",
    "* ```ldavg-5``` - System load average over past 5 minutes\n",
    "* ```ldavg-15``` - System load average over past 15 minutes\n",
    "\n",
    "From ```uptime(1)```:\n",
    "\n",
    "       System load averages is the average number of processes that are either\n",
    "       in a runnable or uninterruptable state.  A process in a runnable  state\n",
    "       is  either using the CPU or waiting to use the CPU.  A process in unin‐\n",
    "       terruptable state is waiting for some I/O access, eg waiting for  disk.\n",
    "       The  averages  are  taken over the three time intervals.  Load averages\n",
    "       are not normalized for the number of CPUs in a system, so a load  aver‐\n",
    "       age  of 1 means a single CPU system is loaded all the time while on a 4\n",
    "       CPU system it means it was idle 75% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.plot_simple_aggregate0(['ldavg-1', 'ldavg-5', 'ldavg-15'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ```runq-sz``` - number of tasks waiting to run\n",
    "* ```plist-sz``` - number of tasks in process list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.plot_simple_aggregate0(['runq-sz', 'plist-sz'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory utilisation statistics\n",
    "* ```memfree``` - kb free memory available\n",
    "* ```memused``` - kb memory used\n",
    "* ```buffers``` - kb kernel buffers buffers\n",
    "* ```cached``` - kb page cache and slabs\n",
    "* ```swpused``` - kb used swap space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.plot_simple_aggregate0(['memfree', 'memused', 'buffers', 'cached', 'swpused'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* ```memused-percent``` - memory used\n",
    "* ```swpused-percent``` - swap used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.plot_simple_aggregate0(['memused-percent', 'swpused-percent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swapping statistics\n",
    "* ```pswpin``` -\n",
    "* ```pswpout``` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.plot_simple_aggregate0(['pswpin', 'pswpout'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task creation and system switching\n",
    "* ```proc``` - tasks created per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.plot_simple_aggregate0(['proc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ```cswch``` - context switches per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.plot_simple_aggregate0(['cswch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Huge pages utilisation\n",
    "* ```hugused``` -\n",
    "* ```hugfree``` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.plot_simple_aggregate0(['hugused', 'hugfree'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ```hugused-percent```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.plot_simple_aggregate0(['hugused-percent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IO and transfar rate statistics\n",
    "* ```tps``` - Transfers per second to physical devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.plot_simple_aggregate0(['tps'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ```rtps``` -\n",
    "* ```wtps``` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.plot_simple_aggregate0(['rtps', 'wtps'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocks per second read|written\n",
    "* ```bread``` -\n",
    "* ```bwrtn``` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.plot_simple_aggregate0(['bread', 'bwrtn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paging statistics\n",
    "\n",
    "* ```pgpgin``` -\n",
    "* ```pgpgout``` -\n",
    "* ```fault``` -\n",
    "* ```majflt``` -\n",
    "* ```pgfree``` -\n",
    "* ```pgscank``` -\n",
    "* ```pgscand``` -\n",
    "* ```pgsteal``` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.plot_simple_aggregate0(['pgpgin', 'pgpgout', 'fault', 'majflt', 'pgfree', 'pgscank', 'pgscand', 'pgsteal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ```vmeff-percent``` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.plot_simple_aggregate0(['vmeff-percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
